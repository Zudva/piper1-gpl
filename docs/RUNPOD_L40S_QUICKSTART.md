# RunPod L40S Quick Start â€” ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚ Ñ **L40S** ($0.71/hr) â€” ÑÐ°Ð¼Ñ‹Ð¼ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¼ GPU Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Piper Ð¿Ñ€Ð¸ Ñ€Ð°Ð·ÑƒÐ¼Ð½Ð¾Ð¹ Ñ†ÐµÐ½Ðµ.

## ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ L40S?

âœ… **48 GB VRAM** â†’ `BATCH_SIZE=80-96` (Ð² 2-3Ã— Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ‡ÐµÐ¼ RTX 4090)  
âœ… **62 GB RAM** â†’ `NUM_WORKERS=4` Ð±ÐµÐ· Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼  
âœ… **~2Ã— Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ RTX 4090** Ð¿Ñ€Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸  
âœ… **$0.71/hr** â†’ Ð´ÐµÑˆÐµÐ²Ð»Ðµ Ñ‡ÐµÐ¼ RTX 5090 ($0.78) Ð¸ H100 ($2.39)  
âœ… **Epoch Ð·Ð° 10 Ñ‡Ð°ÑÐ¾Ð²** (vs 20 Ñ‡Ð°ÑÐ¾Ð² Ð½Ð° RTX 4090)  

**Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ:** ~$17/Ð´ÐµÐ½ÑŒ, ~$512/Ð¼ÐµÑÑÑ†, ~$7/ÑÐ¿Ð¾Ñ…Ð°

---

## 1. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Pod Ð½Ð° RunPod

1. ÐžÑ‚ÐºÑ€Ð¾Ð¹Ñ‚Ðµ [RunPod Console](https://runpod.io/console/pods)
2. **Deploy** â†’ **Pods** â†’ **GPU Pods**
3. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ **L40S** (48 GB VRAM, 62 GB RAM)
4. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ:
   - **Template**: Docker (Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ PyTorch)
   - **Container Disk**: **150 GB** (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼)
   - **Volume Disk**: **50 GB** (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾, Ð´Ð»Ñ Ð¿ÐµÑ€ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…)
   - **Expose Ports**: SSH (22), TensorBoard (6006)

5. **Deploy On-Demand** Ð¸Ð»Ð¸ **Deploy Spot** (Ð´ÐµÑˆÐµÐ²Ð»Ðµ, Ð½Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ñ€ÐµÑ€Ð²Ð°Ñ‚ÑŒÑÑ)

---

## 2. SSH Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ

ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Pod:

1. **Connect** â†’ **Start SSH over exposed TCP port**
2. Ð¡ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ SSH:
   ```bash
   ssh root@XXX.XXX.XXX.XXX -p XXXXX -i ~/.ssh/id_ed25519
   ```

3. Ð˜Ð·Ð²Ð»ÐµÐºÐ¸Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
   ```bash
   export RUNPOD_HOST=XXX.XXX.XXX.XXX  # Ð¸Ð»Ð¸ ssh.runpod.io
   export RUNPOD_PORT=XXXXX
   export RUNPOD_USER=root
   ```

---

## 3. Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° (3 ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹)

```bash
# 1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (Ð²ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÑÐ²Ð¾Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ)
export RUNPOD_HOST=ssh.runpod.io
export RUNPOD_PORT=12345

# 2. ÐŸÐµÑ€Ð²Ð¾Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°
fab setup-runpod

# 3. Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð´Ð°
fab sync-to-runpod
```

---

## 4. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ .env Ñ S3 credentials

```bash
# SSH Ð² pod
fab ssh-runpod

# Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ .env
cat > /workspace/piper1-gpl/.env << 'EOF'
# Timeweb S3
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
AWS_ENDPOINT_URL=https://s3.twcstorage.ru
AWS_DEFAULT_REGION=ru-1-hot
S3_BUCKET=your-bucket-id
S3_PREFIX=piper-training/felix_mirage

# S3 sync
ENABLE_S3_SYNC=1
CHECKPOINT=s3

# L40S optimized settings (48GB VRAM, 62GB RAM)
BATCH_SIZE=80
NUM_WORKERS=4
NUM_DEVICES=1
PRECISION=16-mixed
ACCUM=1
MAX_EPOCHS=10000

# AWS tuning
AWS_MAX_ATTEMPTS=10
AWS_RETRY_MODE=standard
AWS_S3_MAX_CONCURRENCY=10
EOF

exit
```

---

## 5. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ð¸Ð· S3

```bash
fab ssh-runpod

cd /workspace/piper1-gpl

# Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð¸Ð· S3 (ÐµÑÐ»Ð¸ ÑƒÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½)
./script/s3_sync.sh download-dataset

# Ð˜Ð»Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð² S3 Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð°ÑˆÐ¸Ð½Ñ‹ (Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·)
# Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾: ./script/s3_sync.sh upload-dataset /path/to/felix_mirage
```

---

## 6. Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

```bash
# Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 1: Ð§ÐµÑ€ÐµÐ· Fabric (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)
fab start-training --batch-size=80

# Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 2: ÐŸÑ€ÑÐ¼Ð¾ Ð² pod
fab ssh-runpod

docker compose -f deploy/compose/docker-compose.runpod.yml up -d

# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð»Ð¾Ð³Ð¸
docker logs -f piper1-gpl-train-1
```

---

## 7. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³

```bash
# Ð›Ð¾Ð³Ð¸ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
fab ssh-runpod --cmd="docker logs -f piper1-gpl-train-1"

# GPU utilization (Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ 95-100%)
fab ssh-runpod --cmd="watch -n 1 nvidia-smi"

# RAM usage (Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ ~40-50 GB Ð¸Ð· 62 GB)
fab ssh-runpod --cmd="free -h"

# Docker stats
fab ssh-runpod --cmd="docker stats piper1-gpl-train-1"

# Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚Ð¾Ð² Ð² S3
./script/s3_sync.sh list-checkpoints
```

### ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ð°Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ L40S:

```
GPU Utilization: 95-100%
RAM Usage: ~45 GB / 62 GB
VRAM Usage: ~40 GB / 48 GB
Steps/sec: ~2.5-3.0 (vs ~1.2-1.5 Ð½Ð° RTX 4090)
Epoch time: ~10 hours (vs ~20 hours Ð½Ð° RTX 4090)
```

---

## 8. TensorBoard (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)

```bash
# ÐÐ° RunPod pod
fab ssh-runpod

tensorboard --logdir /workspace/piper1-gpl/lightning_logs --host 0.0.0.0 --port 6006

# Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ (Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ðµ)
# ÐžÑ‚ÐºÑ€Ð¾Ð¹Ñ‚Ðµ http://RUNPOD_HOST:6006
```

---

## 9. ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¸ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ

### ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°:

```bash
fab ssh-runpod --cmd="docker compose -f /workspace/piper1-gpl/deploy/compose/docker-compose.runpod.yml down"
```

### Ð’Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ:

```bash
# Ð§ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑÑ Ð¸Ð· S3
fab ssh-runpod --cmd="docker compose -f /workspace/piper1-gpl/deploy/compose/docker-compose.runpod.yml up -d"
```

---

## 10. Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²

```bash
# Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 1: Ð˜Ð· S3 (Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ÑÑ)
./script/s3_sync.sh list-checkpoints
./script/s3_sync.sh download-checkpoint epoch=850-step=403000-val_loss=26.1234.ckpt

# Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚ 2: Ð§ÐµÑ€ÐµÐ· rsync
fab sync-from-runpod --path=lightning_logs
```

---

## ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸

### 1. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ BATCH_SIZE Ð´Ð¾ Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°

```bash
# ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ batch size
export BATCH_SIZE=96
fab start-training --batch-size=96

# Ð•ÑÐ»Ð¸ OOM â†’ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ Ð½Ð° 10-20%
export BATCH_SIZE=80
```

### 2. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ bf16-mixed (Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ)

```bash
export PRECISION=bf16-mixed
fab start-training --batch-size=80 --precision=bf16-mixed

# Ð•ÑÐ»Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ cuFFT â†’ Ð²ÐµÑ€Ð½Ð¸Ñ‚ÐµÑÑŒ Ð½Ð° 16-mixed
export PRECISION=16-mixed
```

### 3. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ NUM_WORKERS (ÐµÑÐ»Ð¸ CPU Ð½Ðµ bottleneck)

```bash
export NUM_WORKERS=6  # Ð±Ñ‹Ð»Ð¾ 4
# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ CPU usage - Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ <90%
fab ssh-runpod --cmd="top"
```

### 4. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ tmpfs Ð´Ð»Ñ ÐºÐµÑˆÐ° (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ RAM)

```yaml
# Ð’ deploy/compose/docker-compose.runpod.yml Ð´Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ:
volumes:
  - type: tmpfs
    target: /data/.cache
    tmpfs:
      size: 20G  # RAM-based cache
```

---

## Troubleshooting

### OOM (Out of Memory) Ð² VRAM

```bash
# Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ batch size
export BATCH_SIZE=64  # Ð±Ñ‹Ð»Ð¾ 80

# Ð˜Ð»Ð¸ Ð²ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ðµ gradient accumulation
export BATCH_SIZE=40
export ACCUM=2  # ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ BS = 40 Ã— 2 = 80
```

### ÐœÐµÐ´Ð»ÐµÐ½Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…

```bash
# Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ num_workers
export NUM_WORKERS=6

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ñ‡Ñ‚Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð½Ð° Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¼ Ð´Ð¸ÑÐºÐµ (Ð½Ðµ NFS)
fab ssh-runpod --cmd="df -h /data"
```

### S3 upload failed

```bash
# Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ retry
export AWS_MAX_ATTEMPTS=20

# ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ credentials
fab ssh-runpod --cmd="aws s3 ls s3://your-bucket/ --endpoint-url=https://s3.twcstorage.ru"
```

---

## Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

### ÐžÑ‚ epoch=749 Ð´Ð¾ epoch=1000 (251 ÑÐ¿Ð¾Ñ…Ð°):

**L40S @ $0.71/hr:**
```
Ð’Ñ€ÐµÐ¼Ñ: 251 ÑÐ¿Ð¾Ñ…Ð¸ Ã— 10 Ñ‡Ð°ÑÐ¾Ð² = 2510 Ñ‡Ð°ÑÐ¾Ð² = ~104 Ð´Ð½Ñ Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾
ÐÐž: Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð½ÑŒÑˆÐµ Ð¿Ñ€Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¸ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð³Ð¾ val_loss
```

**Ð ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ (100 ÑÐ¿Ð¾Ñ…):**
```
Ð’Ñ€ÐµÐ¼Ñ: 100 Ã— 10 = 1000 Ñ‡Ð°ÑÐ¾Ð² = ~42 Ð´Ð½Ñ
Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: 1000 Ã— $0.71 = $710
```

**Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ RTX 4090:**
```
L40S: 100 ÑÐ¿Ð¾Ñ… Ã— 10 Ñ‡Ð°ÑÐ¾Ð² Ã— $0.71 = $710
RTX 4090: 100 ÑÐ¿Ð¾Ñ… Ã— 20 Ñ‡Ð°ÑÐ¾Ð² Ã— $0.50 = $1000
â†’ L40S Ð½Ð° 29% Ð´ÐµÑˆÐµÐ²Ð»Ðµ Ð¿Ñ€Ð¸ 2Ã— ÑÐºÐ¾Ñ€Ð¾ÑÑ‚Ð¸! âœ…
```

---

## ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ ÐºÐ¾Ð¼Ð°Ð½Ð´ (ÐºÐ¾Ð¿Ð¸Ð¿Ð°ÑÑ‚Ð°)

```bash
# 1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
export RUNPOD_HOST=ssh.runpod.io
export RUNPOD_PORT=12345

# 2. ÐŸÐµÑ€Ð²Ð¾Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°
fab setup-runpod
fab sync-to-runpod

# 3. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ .env (SSH Ð² pod, ÑÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð±Ð»Ð¾Ðº Ð¸Ð· ÑˆÐ°Ð³Ð° 4)
fab ssh-runpod
# ... ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ .env ...
exit

# 4. Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚
fab ssh-runpod --cmd="cd /workspace/piper1-gpl && ./script/s3_sync.sh download-dataset"

# 5. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
fab start-training --batch-size=80

# 6. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³
fab ssh-runpod --cmd="docker logs -f piper1-gpl-train-1"
```

---

## Best Practices Ð´Ð»Ñ L40S

1. **Ð’ÑÐµÐ³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ S3 sync** â€” Ð°Ð²Ñ‚Ð¾ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5000 ÑˆÐ°Ð³Ð¾Ð²
2. **ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€ÑŒÑ‚Ðµ GPU utilization** â€” Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ 95-100%, ÐµÑÐ»Ð¸ Ð¼ÐµÐ½ÑŒÑˆÐµ â†’ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ NUM_WORKERS
3. **Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Spot instances** â€” Ð½Ð° 30-40% Ð´ÐµÑˆÐµÐ²Ð»Ðµ, Ð½Ð¾ Ð¼Ð¾Ð³ÑƒÑ‚ Ð¿Ñ€ÐµÑ€Ð²Ð°Ñ‚ÑŒÑÑ
4. **Backup Ð² S3** â€” Ð¿Ñ€Ð¸ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°Ð½Ð¸Ð¸ Spot Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑÑ Ñ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚Ð°
5. **TensorBoard** â€” Ð·Ð°Ð¿ÑƒÑÐºÐ°Ð¹Ñ‚Ðµ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾ÑÐ»Ðµ sync-from-runpod, ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ‚ VRAM

---

## Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ GPU

| GPU | $/Ñ‡Ð°Ñ | Ð­Ð¿Ð¾Ñ…Ð° (Ñ‡Ð°ÑÑ‹) | $/ÑÐ¿Ð¾Ñ…Ð° | Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ | RAM |
|-----|-------|--------------|---------|----------|-----|
| L4 | $0.32 | 20 | $6.40 | 1.0Ã— | 55 GB âœ… |
| RTX 4090 | $0.50 | 18 | $9.00 | 1.1Ã— | 31 GB âš ï¸ |
| RTX 5090 | $0.78 | 12 | $9.36 | 1.6Ã— | 92 GB âœ… |
| **L40S** | **$0.71** | **10** | **$7.10** | **2.0Ã—** | **62 GB âœ…** |
| H100 PCIe | $2.03 | 6 | $12.18 | 3.5Ã— | 176 GB ðŸ’Ž |

**Ð’Ñ‹Ð²Ð¾Ð´:** L40S â€” Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð±Ð°Ð»Ð°Ð½Ñ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ/Ñ†ÐµÐ½Ð° Ð´Ð»Ñ ÑÐµÑ€ÑŒÐµÐ·Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ! ðŸ†

---

## Ð¡Ð¼. Ñ‚Ð°ÐºÐ¶Ðµ

- [DEPLOYMENT.md](DEPLOYMENT.md) â€” ÐžÐ±Ñ‰ÐµÐµ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð¿Ð¾ Ð´ÐµÐ¿Ð»Ð¾ÑŽ
- [S3_INTEGRATION.md](S3_INTEGRATION.md) â€” S3 ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ
- [LOW_RAM_OPTIMIZATION.md](LOW_RAM_OPTIMIZATION.md) â€” ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ low-RAM (Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð´Ð»Ñ L40S!)
