#!/usr/bin/env python3
"""–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è"""
import subprocess
import time
import os

print("üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è")
print("=" * 70)
print()
print("‚ÑπÔ∏è  –û –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ï GPU:")
print()
print("–†–∞–∑–Ω–∏—Ü–∞ –≤ –ø–∞–º—è—Ç–∏ GPU0 (45201MB) vs GPU1 (42235MB) = ~3GB —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ:")
print()
print("  ‚Ä¢ DDP (Distributed Data Parallel) —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±–∞—Ç—á–∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ")
print("  ‚Ä¢ –ù–æ GPU 0 (rank 0) —Ö—Ä–∞–Ω–∏—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
print("    - –ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
print("    - TensorBoard writer")
print("    - –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
print("    - –ß–µ–∫–ø–æ–∏–Ω—Ç –º–µ–Ω–µ–¥–∂–µ—Ä")
print()
print("  ‚Ä¢ –ï—Å–ª–∏ —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è –æ–±–æ–∏—Ö GPU ~100%, –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ")
print("  ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞ 3-5GB –¥–ª—è rank 0 - —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ")
print()
print("–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ - –º–æ–∂–Ω–æ:")
print("  1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å strategy='ddp' –≤–º–µ—Å—Ç–æ 'ddp_find_unused_parameters_true'")
print("  2. –£–º–µ–Ω—å—à–∏—Ç—å batch_size –¥–æ 76 (–¥–µ–ª–∏—Ç—Å—è –Ω–∞ 2 —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ: 38 –Ω–∞ GPU)")
print()
print("=" * 70)
print()

try:
    while True:
        os.system('clear')
        print("\nüìä GPU –°–¢–ê–¢–£–°\n")
        subprocess.run(['nvidia-smi', '--query-gpu=index,name,utilization.gpu,memory.used,memory.total', 
                       '--format=csv,noheader,nounits'])
        print("\n" + "=" * 70)
        print("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥... (Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
        time.sleep(5)
except KeyboardInterrupt:
    print("\n\n‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
