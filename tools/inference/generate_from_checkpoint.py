#!/usr/bin/env python3
"""–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ checkpoint (–±–µ–∑ ONNX)"""

import sys
import json
import torch
import numpy as np
from pathlib import Path
from scipy.io import wavfile

sys.path.insert(0, "/workspace/piper1-gpl/src")

from piper.train.vits.lightning import VitsModel
from piper.phonemize_espeak import EspeakPhonemizer

def load_checkpoint(ckpt_path: str, config_path: str):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ checkpoint"""
    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint: {ckpt_path}")
    checkpoint = torch.load(ckpt_path, map_location='cpu')
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–∑ JSON
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ hyper_parameters
    hparams = checkpoint['hyper_parameters']
    model = VitsModel(**hparams)
    model.load_state_dict(checkpoint['state_dict'])
    model.eval()
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (epoch {checkpoint['epoch']})")
    return model, config

def phonemize_text(text: str, voice: str = "ru", phoneme_id_map: dict = None) -> list[int]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ ID —Ñ–æ–Ω–µ–º"""
    if phoneme_id_map is None:
        raise ValueError("phoneme_id_map required")
    
    phonemizer = EspeakPhonemizer()
    phonemes_list = phonemizer.phonemize(voice, text)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–æ–Ω–µ–º—ã
    phonemes = []
    for sent_phonemes in phonemes_list:
        phonemes.extend(sent_phonemes)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ ID
    phoneme_ids = []
    for phoneme in phonemes:
        if phoneme in phoneme_id_map:
            phoneme_ids.extend(phoneme_id_map[phoneme])
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ–æ–Ω–µ–º–∞: '{phoneme}'")
            phoneme_ids.append(0)
    
    return phoneme_ids

def generate_audio(text: str, model, config: dict, output_path: str):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    
    print(f"üìù –¢–µ–∫—Å—Ç: {text}")
    
    # –§–æ–Ω–µ–º–∏–∑–∞—Ü–∏—è
    print("üî§ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
    phoneme_id_map = config['phoneme_id_map']
    phoneme_ids = phonemize_text(text, voice="ru", phoneme_id_map=phoneme_id_map)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    phoneme_ids_tensor = torch.LongTensor(phoneme_ids).unsqueeze(0)
    phoneme_lengths = torch.LongTensor([len(phoneme_ids)])
    scales = torch.FloatTensor([0.667, 1.0, 0.8])  # noise, length, noise_w
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    print("üé§ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ...")
    with torch.no_grad():
        audio = model.forward(
            phoneme_ids_tensor, 
            phoneme_lengths, 
            scales=scales
        )[0]
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    audio_np = audio.squeeze().cpu().numpy()
    audio_np = np.clip(audio_np, -1.0, 1.0)
    audio_int16 = (audio_np * 32767).astype(np.int16)
    
    sample_rate = config.get('audio', {}).get('sample_rate', 22050)
    wavfile.write(output_path, sample_rate, audio_int16)
    
    duration = len(audio_np) / sample_rate
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    print(f"‚úÖ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫\n")

if __name__ == "__main__":
    # –ü—É—Ç–∏
    ckpt_path = "/workspace/piper1-gpl/lightning_logs/version_15/checkpoints/epoch=851-step=370000-val_loss=27.6856.ckpt"
    config_path = "/workspace/piper1-gpl/felix_mirage_epoch749.onnx.json"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥ –æ—Ç epoch 749
    phrases_file = Path("/workspace/piper1-gpl/test_phrases_ru.txt")
    output_dir = Path("/workspace/piper1-gpl/test_audio_epoch851")
    
    output_dir.mkdir(exist_ok=True)
    
    print("üéôÔ∏è  –ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–£–î–ò–û –ò–ó CHECKPOINT EPOCH 851")
    print("=" * 70)
    print()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model, config = load_checkpoint(ckpt_path, config_path)
    
    # –ß—Ç–µ–Ω–∏–µ —Ñ—Ä–∞–∑
    if phrases_file.exists():
        with open(phrases_file, "r", encoding="utf-8") as f:
            phrases = [line.strip() for line in f if line.strip()]
    else:
        phrases = ["–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏ epoch 851."]
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    for i, phrase in enumerate(phrases, 1):
        output_file = output_dir / f"test_851_{i:02d}.wav"
        try:
            generate_audio(phrase, model, config, str(output_file))
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}\n")
            continue
    
    print(f"üéâ –ì–æ—Ç–æ–≤–æ! –°–æ–∑–¥–∞–Ω–æ {len(list(output_dir.glob('*.wav')))} —Ñ–∞–π–ª–æ–≤")
